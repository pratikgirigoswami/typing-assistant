{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "L750-WOgpZhY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing and Cleaning Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "FzymN_4LpZox",
    "outputId": "bf23e90c-7cde-4741-fee7-79f8cd2d493f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: The Adventures of Sherlock Holmes Author: Arthur Conan Doyle Release Date: November 29, 2002 [EBook #1661] Last Updated: May 20, 2019 Language: English Character set en\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"1661-0.txt\", \"r\", encoding = \"utf8\")\n",
    "\n",
    "# store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "\n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "  data = ' '. join(lines) \n",
    "\n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    "\n",
    "#remove unnecessary spaces \n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ed8BIEMmpZre",
    "outputId": "fe36a845-5712-4bfc-da6a-68f0ab3d3ebb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573660"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtvpKwAgpZuX",
    "outputId": "5c191009-de10-421c-db3b-bfa3155e4b80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[142, 4680, 1, 986, 5, 125, 33, 46, 556, 2164, 2165, 27, 987, 14, 22]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-B46uVBppZxf",
    "outputId": "a488f119-54fd-4ba5-8ca3-905546006d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8624\n"
     ]
    }
   ],
   "source": [
    "len(sequence_data)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breaking Sequence into 4grams Such as Trigrams are Fed is Input data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xNqo2gMIpZ0J",
    "outputId": "de5b3e51-f0cd-45ae-e3a8-7835feb50f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of sequences are:  108955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 142, 4680,    1,  986],\n",
       "       [4680,    1,  986,    5],\n",
       "       [   1,  986,    5,  125],\n",
       "       [ 986,    5,  125,   33],\n",
       "       [   5,  125,   33,   46],\n",
       "       [ 125,   33,   46,  556],\n",
       "       [  33,   46,  556, 2164],\n",
       "       [  46,  556, 2164, 2165],\n",
       "       [ 556, 2164, 2165,   27],\n",
       "       [2164, 2165,   27,  987]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into Input and Target Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x6AyyMeDpZ-g"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15U6yxLhpaBp",
    "outputId": "02c57c09-0716-466c-fae2-9fb228779ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[ 142 4680    1]\n",
      " [4680    1  986]\n",
      " [   1  986    5]\n",
      " [ 986    5  125]\n",
      " [   5  125   33]\n",
      " [ 125   33   46]\n",
      " [  33   46  556]\n",
      " [  46  556 2164]\n",
      " [ 556 2164 2165]\n",
      " [2164 2165   27]]\n",
      "Response:  [ 986    5  125   33   46  556 2164 2165   27  987]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lB80YWpNp0ch",
    "outputId": "1d2c9611-0f91-451a-dee3-1b8a04115121"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creting LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ssiCru2Hp5og"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fdqp2Dl1p5rX",
    "outputId": "21a8295f-7be5-4618-f129-42d7e47877f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             86240     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8624)              8632624   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,767,864\n",
      "Trainable params: 21,767,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing Model Suing Checkpoints #Code Commented Because Model has been trained has saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qoy2YnVMqBP1",
    "outputId": "f2a640a5-afc5-43ce-d1b3-61df23d2a566"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tensorflow.keras.callbacks import ModelCheckpoint\\n\\ncheckpoint = ModelCheckpoint(\"next_words.h5\", monitor=\\'loss\\', verbose=1, save_best_only=True)\\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\\nmodel.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Model and Creating Function to get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FINkb2p1ufGa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "  \n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "  \n",
    "  #print(predicted_word)\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRuYEFVLuf2n",
    "outputId": "c12eebec-34be-43ed-cba0-febb8004b8a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwhile(True):\\n  text = input(\"Enter your line: \")\\n  \\n  if text == \"quit\":\\n      print(\"Execution completed.....\")\\n      break\\n  \\n  else:\\n      try:\\n          text = text.split(\" \")\\n          text = text[-3:]\\n          print(text)\\n        \\n          Predict_Next_Words(model, tokenizer, text)\\n          \\n      except Exception as e:\\n        print(\"Error occurred: \",e)\\n        continue\\n    '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WHile loop to run model and get predictions Without UI\n",
    "'''\n",
    "while(True):\n",
    "  text = input(\"Enter your line: \")\n",
    "  \n",
    "  if text == \"quit\":\n",
    "      print(\"Execution completed.....\")\n",
    "      break\n",
    "  \n",
    "  else:\n",
    "      try:\n",
    "          text = text.split(\" \")\n",
    "          text = text[-3:]\n",
    "          print(text)\n",
    "        \n",
    "          Predict_Next_Words(model, tokenizer, text)\n",
    "          \n",
    "      except Exception as e:\n",
    "        print(\"Error occurred: \",e)\n",
    "        continue\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15156\\4134221737.py\", line 18, in <lambda>\n",
      "    sv.trace(\"w\", lambda name, index, mode, sv=sv: callback(sv))\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15156\\4134221737.py\", line 12, in callback\n",
      "    getpredictions()\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15156\\4134221737.py\", line 45, in getpredictions\n",
      "    output = Predict_Next_Words(model, tokenizer, text)\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15156\\1953996038.py\", line 13, in Predict_Next_Words\n",
      "    preds = np.argmax(model.predict(sequence))\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 1147, in autograph_handler\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n",
      "        outputs = model.predict_step(data)\n",
      "    File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n",
      "        return self(x, training=False)\n",
      "    File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "        raise e.with_traceback(filtered_tb) from None\n",
      "    File \"C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n",
      "        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n",
      "\n",
      "    ValueError: Input 0 of layer \"sequential_2\" is incompatible with the layer: expected shape=(None, 3), found shape=(None, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "import tkinter as tk\n",
    "\n",
    "root= tk.Tk()\n",
    "\n",
    "canvas1 = tk.Canvas(root, width = 400, height = 300,  relief = 'raised')\n",
    "canvas1.pack()\n",
    "\n",
    "def callback(sv):\n",
    "    t=sv.get()\n",
    "    t = t.split(\" \")\n",
    "    if(len(t)>3):\n",
    "        getpredictions()\n",
    "\n",
    "\n",
    "\n",
    "sv = tk.StringVar()\n",
    "\n",
    "sv.trace(\"w\", lambda name, index, mode, sv=sv: callback(sv))\n",
    "\n",
    "label1 = tk.Label(root, text='Typing Assistant')\n",
    "label1.config(font=('helvetica', 14))\n",
    "canvas1.create_window(200, 25, window=label1)\n",
    "\n",
    "label2 = tk.Label(root, text='Start Typing:')\n",
    "label2.config(font=('helvetica', 10))\n",
    "canvas1.create_window(200, 100, window=label2)\n",
    "\n",
    "entry1 = tk.Entry(root, textvariable=sv) \n",
    "canvas1.create_window(200, 140, window=entry1)\n",
    "entry1.focus()\n",
    "\n",
    "label4 = tk.Label(root, text='Predicted Word:')\n",
    "label4.config(font=('helvetica', 10))\n",
    "canvas1.create_window(200, 190, window=label4)\n",
    "\n",
    "\n",
    "def getpredictions():\n",
    "  \n",
    "    text = sv.get()\n",
    "    text = text.split(\" \")\n",
    "\n",
    "    if(len(text)>=3):\n",
    "        text = text[-3:]\n",
    "        \n",
    "        output = Predict_Next_Words(model, tokenizer, text)\n",
    "        label3 = tk.Label(root, text= str(output),font=('helvetica', 10, 'bold'))\n",
    "        canvas1.create_window(200, 230, window=label3)\n",
    "    \n",
    "        canvas1.create_window(200, 230, window=label3)\n",
    "\n",
    "    else:\n",
    "        label3 = tk.Label(root, text=\"Text Too Short\",font=('helvetica', 10, 'bold'))\n",
    "        canvas1.create_window(200, 230, window=label3)\n",
    "        canvas1.create_window(200, 230, window=label3)\n",
    "\n",
    "#Ignore this part\n",
    "'''\n",
    "button1 = tk.Button(root,text='Predict Next Word', command=getpredictions, bg='brown', fg='white', font=('helvetica', 9, 'bold'))\n",
    "canvas1.create_window(200, 180, window=button1)\n",
    "'''\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Next Word Predictor Final Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
